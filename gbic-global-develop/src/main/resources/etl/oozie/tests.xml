<workflow-app xmlns='uri:oozie:workflow:0.5' name='{{ project.prefix }}gbic-${area}-${service}-etl-${ob3}-swf-${fileName}-test-${counter}'>
    <parameters>
        <property>
            <name>counter</name>
        </property>
        <property>
            <name>testType</name>
        </property>
    </parameters>
    <global>
        <job-tracker>${jobTracker}</job-tracker>
        <name-node>${nameNode}</name-node>
    </global>
    
{% if hadoop.cluster.krbenabled %}
{%     set creds=' cred="gbic-cred"' %}
    <credentials>
        <credential name="gbic-cred" type="hcat">
            <property>
                <name>hcat.metastore.uri</name>
                <value>${hive_thrift}</value>
            </property>
            <property>
                <name>hcat.metastore.principal</name>
                <value>${hive_krbprincipal}</value>
            </property>
        </credential>
    </credentials>
    
{% else %}
{%     set creds="" %}
{% endif %}
    <start to="check_exit_condition"/>
    
    <decision name="check_exit_condition">
        <switch>
            <case to="run_test"> 
                ${gbic:existsTestFile(scripts_path, version, fileName, execution, counter) and
                  ( wf:conf('testType') == 'g' or wf:conf('testType') == 'l' and wf:conf('counter') == 1 )}
            </case>
            <default to="end" />
        </switch>
    </decision>
    
    <action name="run_test"{{ creds }}>
        <hive xmlns="uri:oozie:hive-action:0.5">
            <job-xml>${config_path}/hive-site.xml</job-xml>
            <script>${gbic:getTestFilePath(scripts_path, version, fileName, execution, counter)}</script>
            <param>nominalTime=${nominalTime}</param>
            <param>fileName=${fileName}</param>
            <param>gbic_op_id=${gbic_op_id}</param>
            <param>test_id=${counter}</param>
        </hive>
        <ok to="export_test_results" />
        <error to="fail" />
    </action>
    
    <action name='export_test_results'{{ creds }}>
        <sqoop xmlns="uri:oozie:sqoop-action:0.2">
            <job-tracker>${jobTracker}</job-tracker>
            <name-node>${nameNode}</name-node>
            <arg>export</arg>
            <arg>--username</arg>
            <arg>${mysql_user}</arg>
            <arg>--password</arg>
            <arg>${mysql_pass}</arg>
            <arg>--connect</arg>
            <arg>${mysql_url}</arg>
            <arg>--table</arg>
            <arg>test_result</arg>
            <arg>--update-mode</arg>
            <arg>allowinsert</arg>
            <arg>--update-key</arg> 
            <arg>id_filerevision,id_test,test_type,screen_number,test_number_file,test_field,test_field_content</arg>
            <arg>--export-dir</arg>
            <arg>{{ hdfs.testres }}/gbic_op_id=${gbic_op_id}/file=${fileName}/day=${nominalTime}/test_id=${counter}</arg>
            <arg>--input-fields-terminated-by</arg>
            <arg>|</arg>
        </sqoop>
        <ok to="loop" />
        <error to="fail" />
    </action>
    
    <action name="loop">
        <sub-workflow>
            <app-path>${workflow_path}/tests.xml</app-path>
            <propagate-configuration/>
            <configuration>
                <property>
                    <name>counter</name>
                    <value>${counter + 1}</value>
                </property>
            </configuration>
        </sub-workflow>
        <ok to="end"/>
        <error to="fail" />
    </action>
    
    <kill name="fail">
        <message>Map/Reduce failed, error
            message[${wf:errorMessage(wf:lastErrorNode())}]
        </message>
    </kill>
    <end name='end' />
</workflow-app>
